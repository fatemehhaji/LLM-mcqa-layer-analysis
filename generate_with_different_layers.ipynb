{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers  accelerate peft bitsandbytes\n",
    "# !pip install einops\n",
    "# !pip install chardet\n",
    "# ! pip install datasets\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/storage/fatemeh/organized_projects/ed_dictionary_masking/.guide_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/storage/fatemeh/organized_projects/ed_dictionary_masking/.guide_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "/workspace/storage/fatemeh/organized_projects/ed_dictionary_masking/.guide_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "from datasets import load_dataset, load_metric\n",
    "from einops import rearrange, repeat, reduce\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "import json, random\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     #As the model weights are stored using 4 bits and when we want to compute its only going to use 16 bits so we have more accuracy\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     #Quantization parameters are quantized\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "# )\n",
    "\n",
    "# Load base moodel\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # quantization_config=bnb_config,\n",
    "    # use_flash_attention_2=True, # Phi does not support yet.\n",
    "    trust_remote_code=True,\n",
    "    # flash_attn=True,\n",
    "    # flash_rotary=True,\n",
    "    # fused_dense=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    # device_map={\"\": 0},\n",
    "    revision=\"main\",\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>choices</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many legs do horses have?</td>\n",
       "      <td>four</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many eyes do horses have?</td>\n",
       "      <td>two</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many eyes do most spiders have?</td>\n",
       "      <td>eight</td>\n",
       "      <td>[two, four, eight, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many eyes does a tyrannosaurus have?</td>\n",
       "      <td>two</td>\n",
       "      <td>[two, four, eight, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many giraffes are in the average living room?</td>\n",
       "      <td>none</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How many elephants can fit in a freezer?</td>\n",
       "      <td>none</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many tails does a cat have?</td>\n",
       "      <td>one</td>\n",
       "      <td>[two, four, six, three, nine, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many whiskers does a human have?</td>\n",
       "      <td>none</td>\n",
       "      <td>[two, four, six, three, nine, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What does a thermometer measure?</td>\n",
       "      <td>temperature</td>\n",
       "      <td>[humidity, velocity, temperature, pressure]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is rain made of?</td>\n",
       "      <td>water</td>\n",
       "      <td>[water, air, ice, snow, cats, clouds]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How many tails do humans have?</td>\n",
       "      <td>none</td>\n",
       "      <td>[two, four, six, three, nine, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Which gas is generally used to fill balloons t...</td>\n",
       "      <td>helium</td>\n",
       "      <td>[helium, air, oxygen, di-hydrogen monoxide, ni...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Which liquid is usually used to fill swimming ...</td>\n",
       "      <td>water</td>\n",
       "      <td>[water, chlorine, glycerol, oil, nitrogen, non...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Which plants predominantly comprise forests?</td>\n",
       "      <td>trees</td>\n",
       "      <td>[trees, all, seaweed, flowers, moss]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Which organ do humans use to hear?</td>\n",
       "      <td>ears</td>\n",
       "      <td>[eyes, mouth, freezer, legs, nose, foot, brain...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What are people opening when they wake up?</td>\n",
       "      <td>eyes</td>\n",
       "      <td>[eyes, mouth, freezer, legs, nose, foot, brain...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>If a human is standing right-side up, which bo...</td>\n",
       "      <td>foot</td>\n",
       "      <td>[eyes, mouth, nose, foot, brain, ear, head]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What is the color of a human tongue?</td>\n",
       "      <td>red</td>\n",
       "      <td>[red, pink, blue, purple, black, yellow, green...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What color is the sky on a clear sunny day?</td>\n",
       "      <td>blue</td>\n",
       "      <td>[red, blue, purple, black, yellow, green, cyan...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the shape of a wheel?</td>\n",
       "      <td>circle</td>\n",
       "      <td>[grid, decagon, hexagon, rhomboid, icosahedron...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the largest animal in the world?</td>\n",
       "      <td>blue whale</td>\n",
       "      <td>[elephant, deer, goat, sheep, rabbit, dog, mon...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is a chicken hatched from?</td>\n",
       "      <td>egg</td>\n",
       "      <td>[egg, hen, broiler, rooster, caviar, pouch]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How many days are in a leap year?</td>\n",
       "      <td>366</td>\n",
       "      <td>[366, 365, 364, 31, 29, 30, 123, 1]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What sound does a cat make?</td>\n",
       "      <td>meow</td>\n",
       "      <td>[woof, quack, moo, roar, meow, bleat, caw, cry]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What sound does a duck make?</td>\n",
       "      <td>quack</td>\n",
       "      <td>[woof, quack, moo, roar, meow, bleat, caw, cry]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What sound does a cow make?</td>\n",
       "      <td>moo</td>\n",
       "      <td>[woof, quack, moo, roar, meow, bleat, caw, cry]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What is the largest continent on Earth, by area?</td>\n",
       "      <td>Asia</td>\n",
       "      <td>[Asia, Africa, Europe, Australia, North Americ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What color is human blood?</td>\n",
       "      <td>red</td>\n",
       "      <td>[red, blue, purple, black, yellow, green, cyan...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "      <td>[Paris, Moscow, Berlin, Rome, Brussels, Madrid...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What is the capital of Spain?</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>[Paris, Moscow, Berlin, Rome, Brussels, Madrid...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question       answer  \\\n",
       "0                       How many legs do horses have?         four   \n",
       "1                       How many eyes do horses have?          two   \n",
       "2                 How many eyes do most spiders have?        eight   \n",
       "3            How many eyes does a tyrannosaurus have?          two   \n",
       "4   How many giraffes are in the average living room?         none   \n",
       "5            How many elephants can fit in a freezer?         none   \n",
       "6                     How many tails does a cat have?          one   \n",
       "7                How many whiskers does a human have?         none   \n",
       "8                    What does a thermometer measure?  temperature   \n",
       "9                               What is rain made of?        water   \n",
       "10                     How many tails do humans have?         none   \n",
       "11  Which gas is generally used to fill balloons t...       helium   \n",
       "12  Which liquid is usually used to fill swimming ...        water   \n",
       "13       Which plants predominantly comprise forests?        trees   \n",
       "14                 Which organ do humans use to hear?         ears   \n",
       "15         What are people opening when they wake up?         eyes   \n",
       "16  If a human is standing right-side up, which bo...         foot   \n",
       "17               What is the color of a human tongue?          red   \n",
       "18        What color is the sky on a clear sunny day?         blue   \n",
       "19                      What is the shape of a wheel?       circle   \n",
       "20           What is the largest animal in the world?   blue whale   \n",
       "21                    What is a chicken hatched from?          egg   \n",
       "22                  How many days are in a leap year?          366   \n",
       "23                        What sound does a cat make?         meow   \n",
       "24                       What sound does a duck make?        quack   \n",
       "25                        What sound does a cow make?          moo   \n",
       "26   What is the largest continent on Earth, by area?         Asia   \n",
       "27                         What color is human blood?          red   \n",
       "28                     What is the capital of France?        Paris   \n",
       "29                      What is the capital of Spain?       Madrid   \n",
       "\n",
       "                                              choices  \\\n",
       "0                  [two, four, six, three, one, none]   \n",
       "1                  [two, four, six, three, one, none]   \n",
       "2                [two, four, eight, three, one, none]   \n",
       "3                [two, four, eight, three, one, none]   \n",
       "4                  [two, four, six, three, one, none]   \n",
       "5                  [two, four, six, three, one, none]   \n",
       "6            [two, four, six, three, nine, one, none]   \n",
       "7            [two, four, six, three, nine, one, none]   \n",
       "8         [humidity, velocity, temperature, pressure]   \n",
       "9               [water, air, ice, snow, cats, clouds]   \n",
       "10           [two, four, six, three, nine, one, none]   \n",
       "11  [helium, air, oxygen, di-hydrogen monoxide, ni...   \n",
       "12  [water, chlorine, glycerol, oil, nitrogen, non...   \n",
       "13               [trees, all, seaweed, flowers, moss]   \n",
       "14  [eyes, mouth, freezer, legs, nose, foot, brain...   \n",
       "15  [eyes, mouth, freezer, legs, nose, foot, brain...   \n",
       "16        [eyes, mouth, nose, foot, brain, ear, head]   \n",
       "17  [red, pink, blue, purple, black, yellow, green...   \n",
       "18  [red, blue, purple, black, yellow, green, cyan...   \n",
       "19  [grid, decagon, hexagon, rhomboid, icosahedron...   \n",
       "20  [elephant, deer, goat, sheep, rabbit, dog, mon...   \n",
       "21        [egg, hen, broiler, rooster, caviar, pouch]   \n",
       "22                [366, 365, 364, 31, 29, 30, 123, 1]   \n",
       "23    [woof, quack, moo, roar, meow, bleat, caw, cry]   \n",
       "24    [woof, quack, moo, roar, meow, bleat, caw, cry]   \n",
       "25    [woof, quack, moo, roar, meow, bleat, caw, cry]   \n",
       "26  [Asia, Africa, Europe, Australia, North Americ...   \n",
       "27  [red, blue, purple, black, yellow, green, cyan...   \n",
       "28  [Paris, Moscow, Berlin, Rome, Brussels, Madrid...   \n",
       "29  [Paris, Moscow, Berlin, Rome, Brussels, Madrid...   \n",
       "\n",
       "                                             messages  \n",
       "0   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "1   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "2   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "3   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "4   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "5   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "6   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "7   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "8   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "9   [{'role': 'user', 'content': 'Respond to the f...  \n",
       "10  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "11  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "12  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "13  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "14  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "15  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "16  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "17  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "18  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "19  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "20  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "21  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "22  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "23  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "24  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "25  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "26  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "27  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "28  [{'role': 'user', 'content': 'Respond to the f...  \n",
       "29  [{'role': 'user', 'content': 'Respond to the f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/workspace/storage/fatemeh/organized_projects/ed_dictionary_masking/data/mcqa/task.json\"\n",
    "\n",
    "instruction = \"\"\"Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\n",
    "DO NOT RESPOND WITH NUMBERS. only use the options literally.\n",
    "\n",
    "There are examples provided below. Read each example carefully and answer the question in the same format as examples.\"\"\"\n",
    "\n",
    "def generate_messages(row, dataset):\n",
    "    # Randomly sample an example from the dataset\n",
    "    example_row = dataset.sample(1).iloc[0]\n",
    "    example1 = f\"Question: {example_row['question']}\\nOptions: {', '.join(example_row['choices'])}\\nAnswer:\"\n",
    "    answer1 = f\"{example_row['answer']}\\n\"\n",
    "\n",
    "    question_str = f\"Question: {row['question']}\\nOptions: {', '.join(row['choices'])}\\nAnswer:\"\n",
    "    current_example = question_str\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": instruction + example1},\n",
    "        {\"role\": \"assistant\", \"content\": answer1},\n",
    "        {\"role\": \"user\", \"content\": current_example},\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = {\"question\":[], \"answer\":[], \"choices\":[]}\n",
    "for d in data['examples']:\n",
    "    dataset['question'].append(d['input'])\n",
    "    dataset['answer'].append([k for k,v in d['target_scores'].items() if v==1][0])\n",
    "    dataset['choices'].append([k for k,v in d['target_scores'].items()])\n",
    "\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset['messages'] = dataset.apply(lambda row: generate_messages(row, dataset), axis=1)\n",
    "\n",
    "dataset = dataset[:30]\n",
    "dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding(input_ids, max_tokens=8):\n",
    "    with torch.inference_mode():\n",
    "        for _ in range(max_tokens):\n",
    "            # input_ids shape: [1, current_sequence_length]\n",
    "            outputs = model(input_ids)\n",
    "\n",
    "            # outputs.logits shape: [1, current_sequence_length, vocab_size]\n",
    "            next_token_logits = outputs.logits[:, -1, :]\n",
    "            # next_token_logits shape: [1, vocab_size]\n",
    "\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1)\n",
    "            # next_token shape: [1] (the most probable next token ID)\n",
    "            \n",
    "            # stop generation if the model produces the end of sentence </s> token \n",
    "            if next_token == tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "            # rearrange(next_token, 'c -> 1 c'): changes shape to [1, 1] for concatenation\n",
    "            input_ids = torch.cat([input_ids, rearrange(next_token, 'c -> 1 c')], dim=-1)\n",
    "            # input_ids shape after concatenation: [1, current_sequence_length + 1]\n",
    "\n",
    "        generated_text = tokenizer.decode(input_ids[0])\n",
    "        # input_ids[0] shape for decoding: [current_sequence_length]\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "def beam_search_with_layer_v1(input_ids, max_tokens=8, beam_size=2, layer_index=-1):\n",
    "    # Initialize the scores for each beam with zeros. Shape: [beam_size]\n",
    "    beam_scores = torch.zeros(beam_size).to(device)\n",
    "    \n",
    "    # Duplicate the initial sequence for each beam. Shape: [beam_size, seq_length]\n",
    "    beam_sequences = input_ids.clone()\n",
    "    \n",
    "    # Create a boolean mask to keep track of active beams. Shape: [beam_size]\n",
    "    active_beams = torch.ones(beam_size, dtype=torch.bool)\n",
    "    \n",
    "    for step in range(max_tokens):\n",
    "        # Generate model outputs for the current sequences.\n",
    "        # The model is expected to handle batched input, hence the shape of beam_sequences is [beam_size, current_seq_length].\n",
    "        outputs = model(beam_sequences, output_hidden_states=True)\n",
    "        \n",
    "        if layer_index == -1:\n",
    "            # Extract the last logits from the output to get the probabilities for the next token. Shape: [beam_size, vocab_size]\n",
    "            logits = outputs.logits[:, -1, :]\n",
    "        else:\n",
    "            # Get the output of the specified layer\n",
    "            layer_output = outputs.hidden_states[layer_index]\n",
    "            \n",
    "            # Extract the last logits from the output to get the probabilities for the next token.\n",
    "            logits = model.lm_head(layer_output[:, -1, :])\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Calculate the score for each beam and token by flattening the probabilities and selecting the top ones.\n",
    "        # The flattened shape is [beam_size * vocab_size], from which we select the top beam_size scores.\n",
    "        top_scores, top_indices = torch.topk(probs.flatten(), k=beam_size, sorted=False)\n",
    "       \n",
    "        # Map flat indices back to beam and token indices.\n",
    "        # beam_indices is the index in the beam, shape: [beam_size]\n",
    "        # token_indices is the index of the token in the vocabulary, shape: [beam_size]\n",
    "        beam_indices = top_indices // probs.shape[-1]\n",
    "        token_indices = top_indices % probs.shape[-1]\n",
    "        \n",
    "        # Update the sequences with the new tokens at the end. Shape after update: [beam_size, current_seq_length + 1]\n",
    "        # This concatenates the best token for each beam to the end of the sequences.\n",
    "        beam_sequences = torch.cat([\n",
    "            beam_sequences[beam_indices],\n",
    "            token_indices.unsqueeze(-1)\n",
    "        ], dim=-1)\n",
    "\n",
    "        # Update the beam scores with the top scores. Shape: [beam_size]\n",
    "        beam_scores = top_scores\n",
    "        \n",
    "        # Check for the end-of-sequence tokens and update the active beams.\n",
    "        # If a beam produces an EOS token, it is marked as inactive.\n",
    "        active_beams = ~(token_indices == tokenizer.eos_token_id)\n",
    "        \n",
    "        # If all beams are inactive, exit the loop.\n",
    "        if not active_beams.any():\n",
    "            print(\"no active beams\")\n",
    "            break\n",
    "    \n",
    "    # Select the beam with the highest score as the best sequence. Shape: [best_seq_length]\n",
    "    best_beam = beam_scores.argmax()\n",
    "    best_sequence = beam_sequences[best_beam]\n",
    "    \n",
    "    # Decode the best sequence to generate the final text.\n",
    "    generated_text = tokenizer.decode(best_sequence)\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_with_layer_v2(input_ids, answer_token_ids, max_tokens=8, beam_size=2, layer_index=-1):\n",
    "    # Initialize the scores for each beam with zeros. Shape: [beam_size]\n",
    "    beam_scores = torch.zeros(beam_size).to(device)\n",
    "    \n",
    "    # Duplicate the initial sequence for each beam. Shape: [beam_size, seq_length]\n",
    "    beam_sequences = input_ids.clone()\n",
    "    \n",
    "    # Create a boolean mask to keep track of active beams. Shape: [beam_size]\n",
    "    active_beams = torch.ones(beam_size, dtype=torch.bool)\n",
    "    \n",
    "    answer_probability = None\n",
    "    \n",
    "    for step in range(max_tokens):\n",
    "        # Generate model outputs for the current sequences.\n",
    "        outputs = model(beam_sequences, output_hidden_states=True)\n",
    "        \n",
    "        if layer_index == -1:\n",
    "            logits = outputs.logits[:, -1, :]\n",
    "        else:\n",
    "            layer_output = outputs.hidden_states[layer_index]\n",
    "            logits = model.lm_head(layer_output[:, -1, :])\n",
    "        \n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        if answer_probability is None:\n",
    "            answer_probability = probs[0][answer_token_ids[0]].item()\n",
    "        \n",
    "        top_scores, top_indices = torch.topk(probs.flatten(), k=beam_size, sorted=False)\n",
    "       \n",
    "        beam_indices = top_indices // probs.shape[-1]\n",
    "        token_indices = top_indices % probs.shape[-1]\n",
    "        \n",
    "        beam_sequences = torch.cat([\n",
    "            beam_sequences[beam_indices],\n",
    "            token_indices.unsqueeze(-1)\n",
    "        ], dim=-1)\n",
    "        \n",
    "        beam_scores = top_scores\n",
    "        \n",
    "        active_beams = ~(token_indices == tokenizer.eos_token_id)\n",
    "        \n",
    "        if not active_beams.any():\n",
    "            break\n",
    "    \n",
    "    best_beam = beam_scores.argmax()\n",
    "    best_sequence = beam_sequences[best_beam]\n",
    "    \n",
    "    generated_text = tokenizer.decode(best_sequence)\n",
    "    \n",
    "    return generated_text, answer_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_answer(response):\n",
    "    \n",
    "    split_response = response.split('Answer:')\n",
    "    if len(split_response) > 1:\n",
    "        text = split_response[-1].strip()\n",
    "        match = re.search(r'\\[/INST\\](.*?)(?:\\n|</s>|$)', text)\n",
    "        return match.group(1).strip() if match else 'None'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST FOR ONE EXAMPLE\n",
    "\n",
    "# instruction = \"\"\"Interpret each question literally, and as a question about the real world; carefully research each answer, without falling prey to any common myths; and reply “I have no comment” unless you are completely certain of the answer.\n",
    "# Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\n",
    "# DO NOT RESPOND WITH NUMBERS. only use the options literally.\n",
    "\n",
    "# There are examples provided below. Read each example carefully and answer the question in the same format as examples.\"\"\"\n",
    "\n",
    "# # example1 = \"\"\"\n",
    "# # Question: How many legs do horses have?\n",
    "# # Options: two, four, six, three, one, none\\n\"\"\"\n",
    "# # answer1 = \"\"\"Answer: Paris\\n\"\"\"\n",
    "\n",
    "# example1 = \"\"\"\n",
    "# Question: What is the capital of France?\n",
    "# Options: Paris, London, Berlin\\n\"\"\"\n",
    "\n",
    "# answer1 = \"\"\"Answer: Paris\\n\"\"\"\n",
    "\n",
    "# current_example = \"\"\"Question: How many eyes do humans have?\n",
    "# Options: two, four, eight, three, one, none\\n\n",
    "# Answer: \n",
    "# \"\"\"\n",
    "   \n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": instruction + example1},\n",
    "#     {\"role\": \"assistant\", \"content\": answer1},\n",
    "#     {\"role\": \"user\", \"content\": current_example},\n",
    "# ]\n",
    "\n",
    "# input_ids = tokenizer.apply_chat_template(messages, return_tensors='pt')\n",
    "\n",
    "# response = beam_search_with_layer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\n",
      "DO NOT RESPOND WITH NUMBERS. only use the options literally.\n",
      "\n",
      "There are examples provided below. Read each example carefully and answer the question in the same format as examples.Question: What is the capital of France?\n",
      "Options: Paris, Moscow, Berlin, Rome, Brussels, Madrid, Barcelona\n",
      "Answer: [/INST]Paris\n",
      "</s> [INST] Question: On which continent would one find the Nile River?\n",
      "Options: Africa, Asia, South America, North America, Europe\n",
      "Answer: [/INST] continent contin contin contin\n",
      "4.991108653484844e-05\n",
      "##################################################\n",
      "<s> [INST] Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\n",
      "DO NOT RESPOND WITH NUMBERS. only use the options literally.\n",
      "\n",
      "There are examples provided below. Read each example carefully and answer the question in the same format as examples.Question: What is the capital of France?\n",
      "Options: Paris, Moscow, Berlin, Rome, Brussels, Madrid, Barcelona\n",
      "Answer: [/INST]Paris\n",
      "</s> [INST] Question: On which continent would one find the Nile River?\n",
      "Options: Africa, Asia, South America, North America, Europe\n",
      "Answer: [/INST] Africa.\n",
      "\n",
      "\n",
      "0.928238034248352\n"
     ]
    }
   ],
   "source": [
    "# TEST FOR ONE EXAMPLE\n",
    "\n",
    "# instruction = \"\"\"Interpret each question literally, and as a question about the real world; carefully research each answer, without falling prey to any common myths; and reply “I have no comment” unless you are completely certain of the answer.\n",
    "# Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\n",
    "# DO NOT RESPOND WITH NUMBERS. only use the options literally.\n",
    "\n",
    "# There are examples provided below. Read each example carefully and answer the question in the same format as examples.\"\"\"\n",
    "\n",
    "# instruction = \"\"\"Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\n",
    "# DO NOT RESPOND WITH NUMBERS. only use the options literally.\n",
    "\n",
    "# There are examples provided below. Read each example carefully and answer the question in the same format as examples.\"\"\"\n",
    "\n",
    "\n",
    "# example1 = f\"\"\"\n",
    "# Question: {dataset.iloc[4]['question']}\n",
    "# Options: {', '.join(dataset.iloc[4]['choices'])}\"\"\"\n",
    "\n",
    "# answer1 = f\"\"\"Answer: {dataset.iloc[4]['answer']}\\n\"\"\"\n",
    "\n",
    "# current_example = f\"\"\"{dataset.iloc[0]['question']}\n",
    "# Options: {', '.join(dataset.iloc[0]['choices'])}\n",
    "# Answer: \n",
    "# \"\"\"\n",
    "   \n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": instruction + example1},\n",
    "#     {\"role\": \"assistant\", \"content\": answer1},\n",
    "#     {\"role\": \"user\", \"content\": current_example},\n",
    "# ]\n",
    "\n",
    "messages = dataset.iloc[0]['messages']\n",
    "answer = dataset.iloc[0]['answer']\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(messages, return_tensors='pt')\n",
    "answet_token_ids = tokenizer.encode(answer, add_special_tokens=False)\n",
    "\n",
    "response, prob = beam_search_with_layer_v2(input_ids, answer_token_ids=answet_token_ids, max_tokens=4, layer_index=24)\n",
    "print(response)\n",
    "print(prob)\n",
    "print('#'*50)\n",
    "response, prob = beam_search_with_layer_v2(input_ids, answer_token_ids=answet_token_ids, max_tokens=4, layer_index=32)\n",
    "print(response)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 8 START GENERATING.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [10:15<00:00, 20.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 16 START GENERATING.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [09:10<00:00, 18.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 24 START GENERATING.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [08:00<00:00, 16.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 32 START GENERATING.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [09:02<00:00, 18.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>choices</th>\n",
       "      <th>messages</th>\n",
       "      <th>layer_8</th>\n",
       "      <th>layer_16</th>\n",
       "      <th>layer_24</th>\n",
       "      <th>layer_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many legs do horses have?</td>\n",
       "      <td>four</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many eyes do horses have?</td>\n",
       "      <td>two</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many eyes do most spiders have?</td>\n",
       "      <td>eight</td>\n",
       "      <td>[two, four, eight, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many eyes does a tyrannosaurus have?</td>\n",
       "      <td>two</td>\n",
       "      <td>[two, four, eight, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many giraffes are in the average living room?</td>\n",
       "      <td>none</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer  \\\n",
       "0                      How many legs do horses have?   four   \n",
       "1                      How many eyes do horses have?    two   \n",
       "2                How many eyes do most spiders have?  eight   \n",
       "3           How many eyes does a tyrannosaurus have?    two   \n",
       "4  How many giraffes are in the average living room?   none   \n",
       "\n",
       "                                choices  \\\n",
       "0    [two, four, six, three, one, none]   \n",
       "1    [two, four, six, three, one, none]   \n",
       "2  [two, four, eight, three, one, none]   \n",
       "3  [two, four, eight, three, one, none]   \n",
       "4    [two, four, six, three, one, none]   \n",
       "\n",
       "                                            messages  \\\n",
       "0  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "1  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "2  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "3  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "4  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "\n",
       "                                             layer_8  \\\n",
       "0  {'response': '<s> [INST] Respond to the follow...   \n",
       "1  {'response': '<s> [INST] Respond to the follow...   \n",
       "2  {'response': '<s> [INST] Respond to the follow...   \n",
       "3  {'response': '<s> [INST] Respond to the follow...   \n",
       "4  {'response': '<s> [INST] Respond to the follow...   \n",
       "\n",
       "                                            layer_16  \\\n",
       "0  {'response': '<s> [INST] Respond to the follow...   \n",
       "1  {'response': '<s> [INST] Respond to the follow...   \n",
       "2  {'response': '<s> [INST] Respond to the follow...   \n",
       "3  {'response': '<s> [INST] Respond to the follow...   \n",
       "4  {'response': '<s> [INST] Respond to the follow...   \n",
       "\n",
       "                                            layer_24  \\\n",
       "0  {'response': '<s> [INST] Respond to the follow...   \n",
       "1  {'response': '<s> [INST] Respond to the follow...   \n",
       "2  {'response': '<s> [INST] Respond to the follow...   \n",
       "3  {'response': '<s> [INST] Respond to the follow...   \n",
       "4  {'response': '<s> [INST] Respond to the follow...   \n",
       "\n",
       "                                            layer_32  \n",
       "0  {'response': '<s> [INST] Respond to the follow...  \n",
       "1  {'response': '<s> [INST] Respond to the follow...  \n",
       "2  {'response': '<s> [INST] Respond to the follow...  \n",
       "3  {'response': '<s> [INST] Respond to the follow...  \n",
       "4  {'response': '<s> [INST] Respond to the follow...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instruction = \"\"\"Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\n",
    "# DO NOT RESPOND WITH NUMBERS. only use the options literally.\n",
    "\n",
    "# There are examples provided below. Read each example carefully and answer the question in the same format as examples.\"\"\"\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def generate_layer_responses(row, layers):\n",
    "    # example_row = dataset.sample(1).iloc[0]\n",
    "    # example1 = f\"Question: {example_row['question']}\\nOptions: {', '.join(example_row['choices'])}\\nAnswer:\"\n",
    "    # answer1 = f\"{example_row['answer']}\\n\"\n",
    "\n",
    "    # question_str = f\"Question: {row['question']}\\nOptions: {', '.join(row['choices'])}\\nAnswer:\"\n",
    "    # current_example = question_str\n",
    "\n",
    "    # messages = [\n",
    "    #     {\"role\": \"user\", \"content\": instruction + example1},\n",
    "    #     {\"role\": \"assistant\", \"content\": answer1},\n",
    "    #     {\"role\": \"user\", \"content\": current_example},\n",
    "    # ]\n",
    "\n",
    "    responses = {}\n",
    "\n",
    "    messages = row['messages']\n",
    "    answer = row['answer']\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors='pt')\n",
    "    answer_token_ids = tokenizer.encode(answer, add_special_tokens=False)\n",
    "    \n",
    "    for layer in layers:\n",
    "        response, prob = beam_search_with_layer_v2(input_ids, answer_token_ids, max_tokens=4, layer_index=layer)\n",
    "        responses[f'layer_{layer}'] = {'response': response, 'generated_answer': extract_answer(response), 'answer_probability': prob}\n",
    "\n",
    "    return responses\n",
    "\n",
    "layers = [8, 16, 24, 32]\n",
    "\n",
    "for layer in layers:\n",
    "    print(f\"LAYER {layer} START GENERATING.\")\n",
    "    dataset[f'layer_{layer}'] = dataset.progress_apply(lambda row: generate_layer_responses(row, [layer])[f'layer_{layer}'], axis=1)\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': '<s> [INST] Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\\nDO NOT RESPOND WITH NUMBERS. only use the options literally.\\n\\nThere are examples provided below. Read each example carefully and answer the question in the same format as examples.Question: Which is the name of the study of the origin and development of the universe?\\nOptions: cosmology, chemistry, anthropology, cosmetology, physics, mathematics, research, taxonomy\\nAnswer: [/INST]cosmology\\n</s> [INST] Question: How many eyes does a tyrannosaurus have?\\nOptions: two, four, eight, three, one, none\\nAnswer: [/INST] péri︎́️',\n",
       " 'generated_answer': 'péri︎́️',\n",
       " 'answer_probability': 3.1003535696072504e-05}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[3]['layer_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': '<s> [INST] Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\\nDO NOT RESPOND WITH NUMBERS. only use the options literally.\\n\\nThere are examples provided below. Read each example carefully and answer the question in the same format as examples.Question: Which is the name of the study of the origin and development of the universe?\\nOptions: cosmology, chemistry, anthropology, cosmetology, physics, mathematics, research, taxonomy\\nAnswer: [/INST]cosmology\\n</s> [INST] Question: How many eyes does a tyrannosaurus have?\\nOptions: two, four, eight, three, one, none\\nAnswer: [/INST] Noneissen /******/jk',\n",
       " 'generated_answer': 'Noneissen /******/jk',\n",
       " 'answer_probability': 3.085046409978531e-05}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[3]['layer_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': '<s> [INST] Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\\nDO NOT RESPOND WITH NUMBERS. only use the options literally.\\n\\nThere are examples provided below. Read each example carefully and answer the question in the same format as examples.Question: Which is the name of the study of the origin and development of the universe?\\nOptions: cosmology, chemistry, anthropology, cosmetology, physics, mathematics, research, taxonomy\\nAnswer: [/INST]cosmology\\n</s> [INST] Question: How many eyes does a tyrannosaurus have?\\nOptions: two, four, eight, three, one, none\\nAnswer: [/INST] Answer: optionscriptstyle',\n",
       " 'generated_answer': 'None',\n",
       " 'answer_probability': 3.5106149880448356e-05}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[3]['layer_24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': '<s> [INST] Respond to the following question with only one of the options provided. Do not respond with anything else exept exactly the options provided.\\nDO NOT RESPOND WITH NUMBERS. only use the options literally.\\n\\nThere are examples provided below. Read each example carefully and answer the question in the same format as examples.Question: Which is the name of the study of the origin and development of the universe?\\nOptions: cosmology, chemistry, anthropology, cosmetology, physics, mathematics, research, taxonomy\\nAnswer: [/INST]cosmology\\n</s> [INST] Question: How many eyes does a tyrannosaurus have?\\nOptions: two, four, eight, three, one, none\\nAnswer: [/INST] two.\\n\\n',\n",
       " 'generated_answer': 'two.',\n",
       " 'answer_probability': 0.6228059530258179}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[3]['layer_32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>choices</th>\n",
       "      <th>messages</th>\n",
       "      <th>layer_8</th>\n",
       "      <th>layer_16</th>\n",
       "      <th>layer_24</th>\n",
       "      <th>layer_32</th>\n",
       "      <th>answer_probabilities</th>\n",
       "      <th>combined_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many legs do horses have?</td>\n",
       "      <td>four</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>[3.124107752228156e-05, 3.136214945698157e-05,...</td>\n",
       "      <td>{'question': 'How many legs do horses have?', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many eyes do horses have?</td>\n",
       "      <td>two</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>[3.106915391981602e-05, 3.085237767663784e-05,...</td>\n",
       "      <td>{'question': 'How many eyes do horses have?', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many eyes do most spiders have?</td>\n",
       "      <td>eight</td>\n",
       "      <td>[two, four, eight, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>[3.117720552836545e-05, 3.152251156279817e-05,...</td>\n",
       "      <td>{'question': 'How many eyes do most spiders ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many eyes does a tyrannosaurus have?</td>\n",
       "      <td>two</td>\n",
       "      <td>[two, four, eight, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>[3.093479972449131e-05, 3.0848223104840145e-05...</td>\n",
       "      <td>{'question': 'How many eyes does a tyrannosaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many giraffes are in the average living room?</td>\n",
       "      <td>none</td>\n",
       "      <td>[two, four, six, three, one, none]</td>\n",
       "      <td>[{'role': 'user', 'content': 'Respond to the f...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>{'response': '&lt;s&gt; [INST] Respond to the follow...</td>\n",
       "      <td>[3.1579009373672307e-05, 3.729314266820438e-05...</td>\n",
       "      <td>{'question': 'How many giraffes are in the ave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer  \\\n",
       "0                      How many legs do horses have?   four   \n",
       "1                      How many eyes do horses have?    two   \n",
       "2                How many eyes do most spiders have?  eight   \n",
       "3           How many eyes does a tyrannosaurus have?    two   \n",
       "4  How many giraffes are in the average living room?   none   \n",
       "\n",
       "                                choices  \\\n",
       "0    [two, four, six, three, one, none]   \n",
       "1    [two, four, six, three, one, none]   \n",
       "2  [two, four, eight, three, one, none]   \n",
       "3  [two, four, eight, three, one, none]   \n",
       "4    [two, four, six, three, one, none]   \n",
       "\n",
       "                                            messages  \\\n",
       "0  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "1  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "2  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "3  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "4  [{'role': 'user', 'content': 'Respond to the f...   \n",
       "\n",
       "                                             layer_8  \\\n",
       "0  {'response': '<s> [INST] Respond to the follow...   \n",
       "1  {'response': '<s> [INST] Respond to the follow...   \n",
       "2  {'response': '<s> [INST] Respond to the follow...   \n",
       "3  {'response': '<s> [INST] Respond to the follow...   \n",
       "4  {'response': '<s> [INST] Respond to the follow...   \n",
       "\n",
       "                                            layer_16  \\\n",
       "0  {'response': '<s> [INST] Respond to the follow...   \n",
       "1  {'response': '<s> [INST] Respond to the follow...   \n",
       "2  {'response': '<s> [INST] Respond to the follow...   \n",
       "3  {'response': '<s> [INST] Respond to the follow...   \n",
       "4  {'response': '<s> [INST] Respond to the follow...   \n",
       "\n",
       "                                            layer_24  \\\n",
       "0  {'response': '<s> [INST] Respond to the follow...   \n",
       "1  {'response': '<s> [INST] Respond to the follow...   \n",
       "2  {'response': '<s> [INST] Respond to the follow...   \n",
       "3  {'response': '<s> [INST] Respond to the follow...   \n",
       "4  {'response': '<s> [INST] Respond to the follow...   \n",
       "\n",
       "                                            layer_32  \\\n",
       "0  {'response': '<s> [INST] Respond to the follow...   \n",
       "1  {'response': '<s> [INST] Respond to the follow...   \n",
       "2  {'response': '<s> [INST] Respond to the follow...   \n",
       "3  {'response': '<s> [INST] Respond to the follow...   \n",
       "4  {'response': '<s> [INST] Respond to the follow...   \n",
       "\n",
       "                                answer_probabilities  \\\n",
       "0  [3.124107752228156e-05, 3.136214945698157e-05,...   \n",
       "1  [3.106915391981602e-05, 3.085237767663784e-05,...   \n",
       "2  [3.117720552836545e-05, 3.152251156279817e-05,...   \n",
       "3  [3.093479972449131e-05, 3.0848223104840145e-05...   \n",
       "4  [3.1579009373672307e-05, 3.729314266820438e-05...   \n",
       "\n",
       "                                       combined_data  \n",
       "0  {'question': 'How many legs do horses have?', ...  \n",
       "1  {'question': 'How many eyes do horses have?', ...  \n",
       "2  {'question': 'How many eyes do most spiders ha...  \n",
       "3  {'question': 'How many eyes does a tyrannosaur...  \n",
       "4  {'question': 'How many giraffes are in the ave...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_combined_column(row):\n",
    "    return {\n",
    "        'question': row['question'],\n",
    "        'answer': row['answer'],\n",
    "        'generated_answer_8': row['layer_8']['generated_answer'],\n",
    "        'generated_answer_16': row['layer_16']['generated_answer'],\n",
    "        'generated_answer_24': row['layer_24']['generated_answer'],\n",
    "        'generated_answer_32': row['layer_32']['generated_answer']\n",
    "    }\n",
    "\n",
    "def create_probabilities_column(row):\n",
    "    return [\n",
    "        row['layer_8']['answer_probability'],\n",
    "        row['layer_16']['answer_probability'],\n",
    "        row['layer_24']['answer_probability'],\n",
    "        row['layer_32']['answer_probability']\n",
    "    ]\n",
    "\n",
    "\n",
    "dataset['answer_probabilities'] = dataset.apply(create_probabilities_column, axis=1)\n",
    "dataset['combined_data'] = dataset.apply(create_combined_column, axis=1)\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many legs do horses have?\n",
      "Answer: four\n",
      "Generated Answer 8: pérí️́\n",
      "Generated Answer 16: /******/lopeñosaurus\n",
      "Generated Answer 24: None\n",
      "Generated Answer 32: four.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_and_plot_probabilities(index):\n",
    "    combined_data = dataset.loc[index, 'combined_data']\n",
    "    probabilities = dataset.loc[index, 'answer_probabilities']\n",
    "    \n",
    "    print(f\"Question: {combined_data['question']}\")\n",
    "    print(f\"Answer: {combined_data['answer']}\")\n",
    "    for layer in [8, 16, 24, 32]:\n",
    "        print(f\"Generated Answer {layer}: {combined_data[f'generated_answer_{layer}']}\")\n",
    "    \n",
    "    layers = [8, 16, 24, 32]\n",
    "    plt.plot(layers, probabilities, marker='o')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Answer Probability')\n",
    "    plt.title('Answer Probabilities Across Layers')\n",
    "    plt.show()\n",
    "\n",
    "print_and_plot_probabilities(0)  # Pass the index of the row you want to visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('/workspace/storage/fatemeh/organized_projects/NLP_hw2/layers_responses.csv', sep='\\t')\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# dataset = pd.read_csv('/workspace/storage/fatemeh/organized_projects/NLP_hw2/layers_responses.csv', sep='\\t', index_col=0).reset_index(drop=True)\n",
    "# dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 8 Accuracy: 0\n",
      "Layer 16 Accuracy: 16\n",
      "Layer 24 Accuracy: 40\n",
      "Layer 32 Accuracy: 93\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(dataset, layers):\n",
    "    accuracies = {}\n",
    "    \n",
    "    for layer in layers:\n",
    "        correct = 0\n",
    "        total = len(dataset)\n",
    "        \n",
    "        for _, row in dataset.iterrows():\n",
    "            correct_answer = row['answer'].strip().lower()\n",
    "            generated_answer = row[f'layer_{layer}']['generated_answer'].strip().lower()\n",
    "            \n",
    "            if correct_answer in generated_answer:\n",
    "                correct += 1\n",
    "                \n",
    "        accuracy = correct / total\n",
    "        accuracies[layer] = accuracy\n",
    "        print(f\"Layer {layer} Accuracy: {int(accuracy * 100)}\")\n",
    "    \n",
    "layers = [8, 16, 24, 32]\n",
    "calculate_accuracy(dataset, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
